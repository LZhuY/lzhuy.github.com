---
layout: post
title:  "muduo重要组件"
date:   2018-05-15 11:26:00
categories: codereader
tags: codereader
---



前段时间写了套服务端框架，采用reaction模式处理，实现分布式机制。不过总感觉不够精炼、简洁。这个看moduo库希望可以从中学到些东西。
首先从几个重要的组件开始。

1、EventLoop组件，这个应该是moduo库最核心的库。是一个reaction模式的实现。封装了epoll等底层的多路复用IO。

{% highlight ruby %}
	class EventLoop : boost::noncopyable
	{
		public:
		void loop(); ///主循环接口，直到退出。 
		{
			pollReturnTime_ = poller_->poll(kPollTimeMs, &activeChannels_);// 1、处理活跃的channel
			doPendingFunctors(); // 2、处理需要马上触发的CB，runInLoop等接口丢进来的回调，定时器也一样在这里处理。
		}
		void runInLoop(const Functor& cb); ///可以丢一个CB进来到loop线程跑。
	}
{% endhighlight %}

2、Channel组件，每个句柄连接都对应一个Channel，在EventLoop中通过poller拿到活跃的channel列表后，触发channel读回调。
{% highlight ruby %}
	class Channel : boost::noncopyable
	{
		public:
		void handleEvent(Timestamp receiveTime); ///根据poller设置的事件类型，分发事件到读、写、错误处理等接口。
		void setReadCallback(const ReadEventCallback& cb)
		{ readCallback_ = cb; }
		void setWriteCallback(const EventCallback& cb)
		{ writeCallback_ = cb; }
		void setCloseCallback(const EventCallback& cb)
		{ closeCallback_ = cb; }
		void setErrorCallback(const EventCallback& cb)
		{ errorCallback_ = cb; }
		void enableReading() { events_ |= kReadEvent; update(); } //把自己的fd注册到poller中，poller有map<fd,channel>, 根据fd找到活跃channel列表。
		private:
		void set_revents(int revt) { revents_ = revt; } // used by pollers,poller返回活跃的channel列表是，设置事件类型标志到这里。
	}
{% endhighlight %}

3、Accept组件，用于监听端口并处理连接。对channel、loop、Socket几个组件的整合。
{% highlight ruby %}
	Acceptor::Acceptor(EventLoop* loop, const InetAddress& listenAddr, bool reuseport)
	  : loop_(loop),
	    acceptSocket_(sockets::createNonblockingOrDie(listenAddr.family())), //设置监听socket非阻塞。
	    acceptChannel_(loop, acceptSocket_.fd()),//socket赋值给channel，绑定两者关系。
	    listenning_(false),
	    idleFd_(::open("/dev/null", O_RDONLY | O_CLOEXEC))
	{
	  assert(idleFd_ >= 0);
	  acceptSocket_.setReuseAddr(true);
	  acceptSocket_.setReusePort(reuseport);
	  acceptSocket_.bindAddress(listenAddr); //监听绑定端口
	  acceptChannel_.setReadCallback(
	      boost::bind(&Acceptor::handleRead, this)); //poll会先触发channel然后再回调到这里。
	}


	void Acceptor::listen() //开始监听，注册fd到poller
	{
		loop_->assertInLoopThread();
		listenning_ = true;
		acceptSocket_.listen();
		acceptChannel_.enableReading(); ///这里注册到poller了。
	}

	void Acceptor::handleRead()
	{
		loop_->assertInLoopThread();
		InetAddress peerAddr;
		int connfd = acceptSocket_.accept(&peerAddr);
		newConnectionCallback_(connfd, peerAddr); ///这里又回调到上一层即server层，处理新连接。
	}
{% endhighlight %}


4、TcpServer组件，这个是个更高层的封装组件。
{% highlight ruby %}
	class TcpServer : boost::noncopyable
	{
		TcpServer::TcpServer(EventLoop* loop, const InetAddress& listenAddr, const string& nameArg, Option option)
		:loop_(CHECK_NOTNULL(loop)), //loop
		ipPort_(listenAddr.toIpPort()), //监听的端口
		name_(nameArg), //名字
		acceptor_(new Acceptor(loop, listenAddr, option == kReusePort)),//acceptor
		threadPool_(new EventLoopThreadPool(loop, name_)),
		connectionCallback_(defaultConnectionCallback),///新连接处理接口
		messageCallback_(defaultMessageCallback),///消息处理接口
		nextConnId_(1)
		{
			acceptor_->setNewConnectionCallback( ///给acceptor设置新连接回调。
			boost::bind(&TcpServer::newConnection, this, _1, _2));
		}



		void TcpServer::newConnection(int sockfd, const InetAddress& peerAddr) ///处理新连接
		{
			loop_->assertInLoopThread();
			EventLoop* ioLoop = threadPool_->getNextLoop(); //线程级别的负载均衡
			char buf[64];
			snprintf(buf, sizeof buf, "-%s#%d", ipPort_.c_str(), nextConnId_);
			++nextConnId_;
			string connName = name_ + buf;

			LOG_INFO << "TcpServer::newConnection [" << name_
			       << "] - new connection [" << connName
			       << "] from " << peerAddr.toIpPort();
			InetAddress localAddr(sockets::getLocalAddr(sockfd));
			// FIXME poll with zero timeout to double confirm the new connection
			// FIXME use make_shared if necessary
			TcpConnectionPtr conn(new TcpConnection(ioLoop, //new新的conn对象。应该是封装了channel的。这个不用说了。
			                                      connName,
			                                      sockfd,
			                                      localAddr,
			                                      peerAddr));
			connections_[connName] = conn;
			conn->setConnectionCallback(connectionCallback_);//设置各种回调，消息处理回调，连接回调等。
			conn->setMessageCallback(messageCallback_); //这个消息回调应该会触发到上一层，server层的消息处理了。
			conn->setWriteCompleteCallback(writeCompleteCallback_);
			conn->setCloseCallback(
			  boost::bind(&TcpServer::removeConnection, this, _1)); // FIXME: unsafe
			ioLoop->runInLoop(boost::bind(&TcpConnection::connectEstablished, conn)); //TcpConnection::connectEstablished注册到poller中。
		}

		void TcpServer::start()//server开始工作了
		{
			if (started_.getAndSet(1) == 0)
			{
				threadPool_->start(threadInitCallback_);
				assert(!acceptor_->listenning());
				loop_->runInLoop(
				boost::bind(&Acceptor::listen, get_pointer(acceptor_)));
			}
		}
	}
{% endhighlight %}

5、一个简单的使用例子

{% highlight ruby %}

	void onConnection(const TcpConnectionPtr& conn)
	{
		if (conn->connected())
		{
			conn->setTcpNoDelay(true);
		}
	}

	void onMessage(const TcpConnectionPtr& conn, Buffer* buf, Timestamp)
	{
		conn->send(buf);
	}

	int main(int argc, char* argv[])
	{
		if (argc < 4)
		{
			fprintf(stderr, "Usage: server <address> <port> <threads>\n");
		}
		else
		{
			LOG_INFO << "pid = " << getpid() << ", tid = " << CurrentThread::tid();
			Logger::setLogLevel(Logger::WARN);
			const char* ip = argv[1];
			uint16_t port = static_cast<uint16_t>(atoi(argv[2]));
			InetAddress listenAddr(ip, port);///需要监听的端口
			int threadCount = atoi(argv[3]);

			EventLoop loop;// loop组件
			TcpServer server(&loop, listenAddr, "PingPong");//server组件，初始化acceptor_等组件，给acceptor_注册回调接口。
			server.setConnectionCallback(onConnection); //server组件设置回调接口
			server.setMessageCallback(onMessage);
			if (threadCount > 1)
			{
				server.setThreadNum(threadCount);
			}
			server.start();//注册到poller，开始工作等待消息。
			loop.loop(); //开始主循环。
		}
	}
{% endhighlight %}


6、总结
moduo整体框架设计非常简洁，各个模块分工明确。并且模块都有设置回调函数的接口，供给外界组成回调函数。
就像是提供了插座，使用者用不同功能的插头插入就可以实现不同需求，非常的灵活方便。各个模块间的解耦设计的非常好。